{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib as pg\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import os\n",
    "import datetime\n",
    "import pyproj\n",
    "from scipy import stats\n",
    "import gzip\n",
    "\n",
    "import dataclasses as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torprob_file = pathlib.Path('./pp_forecasts/regProbs/19500428_1630.npz')\n",
    "ndfd_area = 25\n",
    "nsims = 10000\n",
    "tornado_direction_distribution = stats.norm(50,15)\n",
    "coolseason = [1,2,3,4,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['IMPACTSDATA'] = \"../impacts-data\"\n",
    "impacts_data_root = pathlib.Path(os.environ['IMPACTSDATA'],\"pas-input-data\").expanduser().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pp_file(file):\n",
    "    \"\"\" Read a PP file and format properly for the PAS \"\"\"\n",
    "    data = np.load(file)\n",
    "    probs = data['fcst']*100\n",
    "    vals = np.where(probs==0, -1.,probs)\n",
    "    \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = pathlib.Path(\"..\", \"output\").resolve()\n",
    "outdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup Simulation ###\n",
    "# Determine Date/Time of outlook from filename\n",
    "date_in_name = torprob_file.name.split(\"/\")[-1].split(\".\")[0]\n",
    "dt = datetime.datetime.strptime(date_in_name, \"%Y%m%d_%H%M\")\n",
    "outfile = outdir.joinpath(f\"{dt.strftime('%Y%m%d%H%M')}_pp.psv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torn = read_pp_file(torprob_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  2.,  5., 10.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(torn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    continuous_torn = dc.make_continuous(torn)\n",
    "except ValueError:\n",
    "    import sys\n",
    "    if torn.max() == 0:\n",
    "        with gzip.GzipFile(outfile, \"w\") as OUT:\n",
    "            OUT.write(\"\".encode())\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        print(\"There was an uncaught error converting to continuous probabilities. Exiting...\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, 10])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigtorn = read_pp_file(pathlib.Path('./pp_forecasts/sigProbs/19500428_1630.npz')).astype(int)\n",
    "np.unique(sigtorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigtorn[sigtorn > 0] = 1\n",
    "np.unique(sigtorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sigtorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  2,  5, 10])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(torn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make double sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torn.max() >= 30) and (sigtorn.max() > 0):\n",
    "    sigtorn[torn >= 15] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigtorn_1d = sigtorn.ravel()\n",
    "usesig = True if (dt.month in coolseason) or (sigtorn.max() > 0) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sigtorn_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10,000 Tornado Count Simulations\n"
     ]
    }
   ],
   "source": [
    "### Run Tornado Count Simulation ###\n",
    "print(f\"Running {nsims:,d} Tornado Count Simulations\")\n",
    "tornado_dists = dc.TornadoDistributions()\n",
    "counts = np.zeros((5, nsims), dtype=int)\n",
    "counts[0, :] = (tornado_dists.f02.rvs(nsims) * ndfd_area * (torn == 2).sum()).astype(int)\n",
    "counts[1, :] = (tornado_dists.f05.rvs(nsims) * ndfd_area * (torn == 5).sum()).astype(int)\n",
    "counts[2, :] = (tornado_dists.f10.rvs(nsims) * ndfd_area * (torn == 10).sum()).astype(int)\n",
    "counts[3, :] = (tornado_dists.f15.rvs(nsims) * ndfd_area * (torn == 15).sum()).astype(int)\n",
    "counts[4, :] = (tornado_dists.f30.rvs(nsims) * ndfd_area * (torn >= 30).sum()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*counts* is a 5x10000 array to hold the number of tors for each sim for each prob level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([234419, 227955, 330934, 338544, 381482, 341700, 404000, 292294,\n",
       "       319225, 207572])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.weighted_choice(2,torn,continuous_torn,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup Impact Simulation ###\n",
    "igrids = dc.ImpactGrids(impacts_data_root)\n",
    "\n",
    "scounts = counts.sum(axis=1)\n",
    "inds02 = dc.weighted_choice(prob=2, probs=torn, cprobs=continuous_torn, size=scounts[0])\n",
    "inds05 = dc.weighted_choice(prob=5, probs=torn, cprobs=continuous_torn, size=scounts[1])\n",
    "inds10 = dc.weighted_choice(prob=10, probs=torn, cprobs=continuous_torn, size=scounts[2])\n",
    "inds15 = dc.weighted_choice(prob=15, probs=torn, cprobs=continuous_torn, size=scounts[3])\n",
    "inds30 = dc.weighted_choice(prob=30, probs=torn, cprobs=continuous_torn, size=scounts[4])\n",
    "inds = dc.flatten_list([inds02, inds05, inds10, inds15, inds30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigtorn_1d[365315] == -1\n",
    "#np.where(sigtorn_1d == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_sig_inds = sigtorn_1d[inds] == -1\n",
    "single_sig_inds = sigtorn_1d[inds] == 1\n",
    "double_sig_inds = sigtorn_1d[inds] == 2\n",
    "\n",
    "if usesig:\n",
    "    single_sig_inds += non_sig_inds\n",
    "    non_sig_inds[:] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(non_sig_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Locations\n",
    "non_sig_loc_inds = inds[non_sig_inds]\n",
    "single_sig_loc_inds = inds[single_sig_inds]\n",
    "double_sig_loc_inds = inds[double_sig_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sig_loc_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Ratings\n",
    "_mags=[0, 1, 2, 3, 4, 5]\n",
    "non_sig_ratings = np.random.choice(_mags, size=non_sig_inds.sum(),\n",
    "                                   replace=True, p=tornado_dists.r_nonsig)\n",
    "single_sig_ratings = np.random.choice(_mags, size=single_sig_inds.sum(),\n",
    "                                      replace=True, p=tornado_dists.r_singlesig)\n",
    "double_sig_ratings = np.random.choice(_mags, size=double_sig_inds.sum(),\n",
    "                                      replace=True, p=tornado_dists.r_doublesig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sig_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Distances\n",
    "non_sig_distances = dc.get_distances(non_sig_ratings, tornado_dists)\n",
    "single_sig_distances = dc.get_distances(single_sig_ratings, tornado_dists)\n",
    "double_sig_distances = dc.get_distances(double_sig_ratings, tornado_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sig_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulations...\n",
      "    Non Sig...\n",
      "    Single Sig...\n",
      "    Double Sig...\n",
      "Splitting simulations back out...\n",
      "Writing Out gzipped PSV file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running simulations...\")\n",
    "print(\"    Non Sig...\")\n",
    "non_sig = dc.simulate(non_sig_loc_inds, non_sig_distances,\n",
    "                      non_sig_ratings, tornado_direction_distribution, igrids)\n",
    "print(\"    Single Sig...\")\n",
    "single_sig = dc.simulate(single_sig_loc_inds, single_sig_distances,\n",
    "                         single_sig_ratings, tornado_direction_distribution, igrids)\n",
    "print(\"    Double Sig...\")\n",
    "double_sig = dc.simulate(double_sig_loc_inds, double_sig_distances,\n",
    "                         double_sig_ratings, tornado_direction_distribution, igrids)\n",
    "\n",
    "print(\"Splitting simulations back out...\")\n",
    "simulated_tornadoes = dc.flatten_list([non_sig, single_sig, double_sig])\n",
    "np.random.shuffle(simulated_tornadoes)\n",
    "_sims = np.split(simulated_tornadoes, counts.sum(axis=0).cumsum())[:-1]\n",
    "realizations = dc.Realizations([dc.SyntheticTornadoRealization(_sim, i+1) for i, _sim in enumerate(_sims)])\n",
    "\n",
    "\n",
    "print(\"Writing Out gzipped PSV file...\")\n",
    "with gzip.GzipFile(outfile, \"w\") as OUT:\n",
    "    OUT.write(realizations.as_psv.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simulated_tornadoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "igrids = dc.ImpactGrids(impacts_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'ABQ', 'ABR', 'AKQ', 'ALY', 'AMA', 'APX', 'ARX', 'BGM', 'BIS',\n",
       "       'BMX', 'BOI', 'BOU', 'BOX', 'BRO', 'BTV', 'BUF', 'CAE', 'CAR',\n",
       "       'CHS', 'CLE', 'CRP', 'CTP', 'CYS', 'DDC', 'DLH', 'DMX', 'DTX',\n",
       "       'DVN', 'EAX', 'EKA', 'EPZ', 'EWX', 'FFC', 'FGF', 'FGZ', 'FSD',\n",
       "       'FWD', 'GGW', 'GID', 'GJT', 'GLD', 'GRB', 'GRR', 'GSP', 'GYX',\n",
       "       'HGX', 'HNX', 'HUN', 'ICT', 'ILM', 'ILN', 'ILX', 'IND', 'IWX',\n",
       "       'JAN', 'JAX', 'JKL', 'KEY', 'LBF', 'LCH', 'LIX', 'LKN', 'LMK',\n",
       "       'LOT', 'LOX', 'LSX', 'LUB', 'LWX', 'LZK', 'MAF', 'MEG', 'MFL',\n",
       "       'MFR', 'MHX', 'MKX', 'MLB', 'MOB', 'MPX', 'MQT', 'MRX', 'MSO',\n",
       "       'MTR', 'OAX', 'OHX', 'OKX', 'OTX', 'OUN', 'PAH', 'PBZ', 'PDT',\n",
       "       'PHI', 'PQR', 'PSR', 'PUB', 'RAH', 'REV', 'RLX', 'RNK', 'SEW',\n",
       "       'SGF', 'SGX', 'SHV', 'SJT', 'SJU', 'TAE', 'TBW'], dtype='<U21')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(igrids.wfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCWA = pathlib.Path('../impacts-data/pas-input-data/cwas.npz')\n",
    "wfo = np.load(newCWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwas\n"
     ]
    }
   ],
   "source": [
    "for key in wfo.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/josephpicca/Desktop/work2020/cimms-spc/IMPACTS-work/impacts/output/195004281630_pp.psv.gz')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

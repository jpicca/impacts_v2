{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infinite-impression",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T21:48:45.825134Z",
     "iopub.status.busy": "2021-08-03T21:48:45.824877Z",
     "iopub.status.idle": "2021-08-03T21:48:54.308549Z",
     "shell.execute_reply": "2021-08-03T21:48:54.307967Z",
     "shell.execute_reply.started": "2021-08-03T21:48:45.825072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pygridder import pygridder as pgrid\n",
    "import pyproj\n",
    "import pathlib\n",
    "\n",
    "import multiprocessing.popen_spawn_posix\n",
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "import skimage.morphology as skmorph\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c448377-759f-405e-bf0e-bac32a37e480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T22:45:19.414211Z",
     "iopub.status.busy": "2021-08-03T22:45:19.413993Z",
     "iopub.status.idle": "2021-08-03T22:45:19.417268Z",
     "shell.execute_reply": "2021-08-03T22:45:19.416402Z",
     "shell.execute_reply.started": "2021-08-03T22:45:19.414188Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dclasses as dc\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef760fde-4c1a-43ef-9663-b385e944ec0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T20:28:48.048321Z",
     "iopub.status.busy": "2021-08-04T20:28:48.045636Z",
     "iopub.status.idle": "2021-08-04T20:28:48.224888Z",
     "shell.execute_reply": "2021-08-04T20:28:48.224295Z",
     "shell.execute_reply.started": "2021-08-04T20:28:48.048287Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pygrib as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "conceptual-affair",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T17:16:49.889145Z",
     "iopub.status.busy": "2021-08-04T17:16:49.888921Z",
     "iopub.status.idle": "2021-08-04T17:16:51.290614Z",
     "shell.execute_reply": "2021-08-04T17:16:51.289807Z",
     "shell.execute_reply.started": "2021-08-04T17:16:49.889121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(processes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "typical-roulette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T21:12:31.628530Z",
     "iopub.status.busy": "2021-08-04T21:12:31.628278Z",
     "iopub.status.idle": "2021-08-04T21:12:32.231312Z",
     "shell.execute_reply": "2021-08-04T21:12:32.230037Z",
     "shell.execute_reply.started": "2021-08-04T21:12:31.628509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vulnerable-plane",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T21:50:57.657797Z",
     "iopub.status.busy": "2021-08-03T21:50:57.657502Z",
     "iopub.status.idle": "2021-08-03T21:50:59.308107Z",
     "shell.execute_reply": "2021-08-03T21:50:59.307331Z",
     "shell.execute_reply.started": "2021-08-03T21:50:57.657766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Variables & Pre-Processing for PP forecast\n",
    "dx = 5 # delta x\n",
    "selem = skmorph.disk(40 / dx) # morphology disk\n",
    "\n",
    "ndfd_path = pathlib.Path('../scripts/impacts-data/pas-input-data/ndfd.npz').resolve()\n",
    "with np.load(ndfd_path) as NPZ:\n",
    "    lons = NPZ['lons']\n",
    "    lats = NPZ['lats']\n",
    "    \n",
    "G = pgrid.Gridder(tx=lons, ty=lats, dx=dx/100)\n",
    "\n",
    "dateparser = lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S') + dt.timedelta(hours=6)\n",
    "data_path = pathlib.Path('../../../gen-assets/1950-2019_tors_CONUS.csv')\n",
    "\n",
    "df = pd.read_csv(data_path, parse_dates=[['date','time']], date_parser=dateparser, index_col=0, keep_date_col=True)\n",
    "df = df.reset_index()\n",
    "\n",
    "all_di = {0: 0.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}\n",
    "sig_di = {0: 0.0, 1: 0.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}\n",
    "df['all_weight'] = df['mag'].map(all_di).fillna(df['mag'])\n",
    "df['sig_weight'] = df['mag'].map(sig_di).fillna(df['mag'])\n",
    "\n",
    "outlook_time = '1200'\n",
    "\n",
    "# Create date array\n",
    "my_hour = dt.datetime.strptime(outlook_time, '%H%M').hour\n",
    "my_minute = dt.datetime.strptime(outlook_time, '%H%M').minute\n",
    "\n",
    "bdt = dt.datetime(1950,1,1,my_hour,my_minute)\n",
    "edt = dt.datetime(2019,12,31,my_hour,my_minute)\n",
    "\n",
    "# Create list index of datetimes with a frequency of one per day\n",
    "dts = pd.date_range(bdt, edt, freq='D')\n",
    "bdts, edts = dts[:-1],dts[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ae585ae-8bde-42a3-b2da-09b6880ba95b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T20:42:07.859171Z",
     "iopub.status.busy": "2021-08-04T20:42:07.858952Z",
     "iopub.status.idle": "2021-08-04T20:42:07.876027Z",
     "shell.execute_reply": "2021-08-04T20:42:07.874232Z",
     "shell.execute_reply.started": "2021-08-04T20:42:07.859146Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PAS Global Variables and Pre-Processing\n",
    "### Parse CLI Arguments ###\n",
    "\n",
    "ndfd_area = 25\n",
    "nsims = 10000\n",
    "tornado_direction_distribution = stats.norm(50, 15)\n",
    "coolseason = [1, 2, 3, 4, 11, 12]\n",
    "\n",
    "impacts_data_root = pathlib.Path('../scripts/impacts-data/pas-input-data/')\n",
    "outdir = pathlib.Path('./PAS-climo/',\"output\").resolve()\n",
    "outdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-ontario",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T17:35:02.833993Z",
     "iopub.status.busy": "2021-08-03T17:35:02.833784Z",
     "iopub.status.idle": "2021-08-03T17:35:02.859834Z",
     "shell.execute_reply": "2021-08-03T17:35:02.859128Z",
     "shell.execute_reply.started": "2021-08-03T17:35:02.833971Z"
    }
   },
   "source": [
    "- loop through one tor\n",
    "- add days to a das delayed if they include tornadoes\n",
    "- once delayed arr is of length 12, run a compute...\n",
    "    - Create tor and sigtor prob arrays\n",
    "    - run PAS on these prob arrays and save psv.gz files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e954b-4bea-475d-bb7b-29c17b971917",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Current Implementation of Dask to parallelize via grouping PP creation in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06431821-c0e5-4c52-9dcf-c76fc080c051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T17:38:03.390276Z",
     "iopub.status.busy": "2021-08-04T17:38:03.390046Z",
     "iopub.status.idle": "2021-08-04T17:38:10.770265Z",
     "shell.execute_reply": "2021-08-04T17:38:10.769720Z",
     "shell.execute_reply.started": "2021-08-04T17:38:03.390252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.3 s, sys: 118 ms, total: 8.42 s\n",
      "Wall time: 7.38 s\n"
     ]
    }
   ],
   "source": [
    "## Baseline loop\n",
    "\n",
    "%%time\n",
    "for bdt, edt in zip(bdts[:100],edts[:100]):\n",
    "    _df = df[(df['date_time'] >= bdt) & (df['date_time'] < edt) & (df['all_weight'] == 1.0)]\n",
    "    if _df.empty:\n",
    "        continue\n",
    "    else:\n",
    "        processPP(_df,bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dress-extreme",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T20:51:15.352579Z",
     "iopub.status.busy": "2021-08-04T20:51:15.352349Z",
     "iopub.status.idle": "2021-08-04T20:51:23.596622Z",
     "shell.execute_reply": "2021-08-04T20:51:23.595774Z",
     "shell.execute_reply.started": "2021-08-04T20:51:15.352554Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.31 s, sys: 2.17 s, total: 5.47 s\n",
      "Wall time: 8.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "da_list = []\n",
    "\n",
    "for bdt, edt in zip(bdts[:100],edts[:100]):\n",
    "    _df = df[(df['date_time'] >= bdt) & (df['date_time'] < edt) & (df['all_weight'] == 1.0)]\n",
    "    if _df.empty:\n",
    "        continue\n",
    "    else:\n",
    "        da = dask.delayed(processPP)(_df,bdt)\n",
    "        da_list.append(da)\n",
    "        \n",
    "        if len(da_list) == 12:\n",
    "            das = dask.compute(da_list)\n",
    "            \n",
    "            da_list = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2a9d34f-3ffa-4a77-bc9f-bc5e40cd1b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T20:51:11.821252Z",
     "iopub.status.busy": "2021-08-04T20:51:11.821024Z",
     "iopub.status.idle": "2021-08-04T20:51:11.843272Z",
     "shell.execute_reply": "2021-08-04T20:51:11.837677Z",
     "shell.execute_reply.started": "2021-08-04T20:51:11.821227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runPAS(all_fcst, sig_fcst, date_in_name):\n",
    "    \n",
    "    outfile = outdir.joinpath(f\"{date_in_name.strftime('%Y%m%d%H%M%S')}_ts.psv.gz\")\n",
    "    \n",
    "    torn = all_fcst*100\n",
    "    continuous_torn = dc.make_continuous(torn)\n",
    "    sigtorn = sig_fcst*100\n",
    "    \n",
    "    sigtorn[sigtorn > 0] = 1\n",
    "    if (torn.max() >= 30) and (sigtorn.max() > 0):\n",
    "        sigtorn[torn >= 15] += 1\n",
    "    sigtorn_1d = sigtorn.ravel()\n",
    "    usesig = True if (date_in_name.month in coolseason) or (sigtorn.max() > 0) else False\n",
    "    \n",
    "    tornado_dists = dc.TornadoDistributions()\n",
    "    counts = np.zeros((5, nsims), dtype=int)\n",
    "    counts[0, :] = (tornado_dists.f02.rvs(nsims) * ndfd_area * (torn == 2).sum()).astype(int)\n",
    "    counts[1, :] = (tornado_dists.f05.rvs(nsims) * ndfd_area * (torn == 5).sum()).astype(int)\n",
    "    counts[2, :] = (tornado_dists.f10.rvs(nsims) * ndfd_area * (torn == 10).sum()).astype(int)\n",
    "    counts[3, :] = (tornado_dists.f15.rvs(nsims) * ndfd_area * (torn == 15).sum()).astype(int)\n",
    "    counts[4, :] = (tornado_dists.f30.rvs(nsims) * ndfd_area * (torn >= 30).sum()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "durable-future",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T20:51:11.959341Z",
     "iopub.status.busy": "2021-08-04T20:51:11.959131Z",
     "iopub.status.idle": "2021-08-04T20:51:11.973427Z",
     "shell.execute_reply": "2021-08-04T20:51:11.972883Z",
     "shell.execute_reply.started": "2021-08-04T20:51:11.959318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def processPP(_df,date_in_name):\n",
    "    \n",
    "    lon1 = _df.slon.values\n",
    "    lat1 = _df.slat.values\n",
    "    lon2 = _df.elon.values\n",
    "    lat2 = _df.elat.values\n",
    "\n",
    "    # Find/remove/replace missing data\n",
    "    keep = ~np.logical_or(lon1 == 0, lat1 == 0)\n",
    "    lon1 = lon1[keep]\n",
    "    lat1 = lat1[keep]\n",
    "    lon2 = lon2[keep]\n",
    "    lat2 = lat2[keep]\n",
    "    lon2[lon2 == 0] = lon1[lon2 == 0]\n",
    "    lat2[lat2 == 0] = lat1[lat2 == 0]\n",
    "\n",
    "    # Grid tornadoes\n",
    "    tornlines = G.grid_lines(sxs=lon1, sys=lat1, exs=lon2, eys=lat2)\n",
    "    all_mags = _df['all_weight']\n",
    "    sig_mags = _df['sig_weight']\n",
    "    all_fcst = G.make_empty_grid(dtype='float')\n",
    "    sig_fcst = G.make_empty_grid(dtype='float')\n",
    "    \n",
    "    for tornline, all_mag, sig_mag in zip(tornlines, all_mags, sig_mags):\n",
    "        all_fcst[tornline] = all_mag\n",
    "        sig_fcst[tornline] = sig_mag\n",
    "    \n",
    "    # Make practically perfect forecast\n",
    "    all_fcst = skmorph.binary_dilation(all_fcst, selem).astype(float)\n",
    "    sig_fcst = skmorph.binary_dilation(sig_fcst, selem).astype(float)\n",
    "\n",
    "    #print(np.max(fcst))\n",
    "    all_fcst = ndimage.gaussian_filter(all_fcst, 120/dx)\n",
    "    sig_fcst = ndimage.gaussian_filter(sig_fcst, 120/dx)\n",
    "    \n",
    "    # Degrade continuous probs into SPC prob\n",
    "    # Uncomment if regular probs\n",
    "    all_fcst[all_fcst < 0.02] = 0\n",
    "    all_fcst[np.logical_and(all_fcst < 0.05, all_fcst >= 0.02)] = 0.02\n",
    "    all_fcst[np.logical_and(all_fcst < 0.10, all_fcst >= 0.05)] = 0.05\n",
    "    all_fcst[np.logical_and(all_fcst < 0.15, all_fcst >= 0.10)] = 0.10\n",
    "    all_fcst[np.logical_and(all_fcst < 0.30, all_fcst >= 0.15)] = 0.15\n",
    "    all_fcst[np.logical_and(all_fcst < 0.45, all_fcst >= 0.30)] = 0.30\n",
    "    all_fcst[all_fcst >= 0.45] = 0.45\n",
    "\n",
    "    # Uncomment if sigtor probs\n",
    "    sig_fcst[sig_fcst < 0.10] = 0\n",
    "    sig_fcst[sig_fcst >= 0.10] = 0.10\n",
    "    \n",
    "    # Have this function call PAS function here\n",
    "    runPAS(all_fcst, sig_fcst, date_in_name)\n",
    "    \n",
    "    #return all_fcst, sig_fcst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e521d0e-55d0-4c29-8cfd-cb9833e2697b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trying different ways to chunk data for dask parallelizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "361c85c2-b571-4b0f-af7f-30809948977b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T17:51:27.836366Z",
     "iopub.status.busy": "2021-08-04T17:51:27.836150Z",
     "iopub.status.idle": "2021-08-04T17:51:35.378710Z",
     "shell.execute_reply": "2021-08-04T17:51:35.377546Z",
     "shell.execute_reply.started": "2021-08-04T17:51:27.836342Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 2.91 s, total: 6.32 s\n",
      "Wall time: 7.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "finished = dask.compute(anom(bdts,edts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0345c95d-c1ef-48c0-8fa4-f2d22bc44ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T17:51:24.012013Z",
     "iopub.status.busy": "2021-08-04T17:51:24.011751Z",
     "iopub.status.idle": "2021-08-04T17:51:24.059407Z",
     "shell.execute_reply": "2021-08-04T17:51:24.054289Z",
     "shell.execute_reply.started": "2021-08-04T17:51:24.011982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def anom(bdts,edts):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for bdt, edt in zip(bdts[:100],edts[:100]):\n",
    "        _df = df[(df['date_time'] >= bdt) & (df['date_time'] < edt) & (df['all_weight'] == 1.0)]\n",
    "        if _df.empty:\n",
    "            continue\n",
    "        else:\n",
    "            result = processPP_da(_df,bdt)\n",
    "            \n",
    "        results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bfe6f316-9ad0-4ece-802c-b184e1185249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T17:37:16.949738Z",
     "iopub.status.busy": "2021-08-04T17:37:16.949515Z",
     "iopub.status.idle": "2021-08-04T17:37:16.962229Z",
     "shell.execute_reply": "2021-08-04T17:37:16.961620Z",
     "shell.execute_reply.started": "2021-08-04T17:37:16.949715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def processPP_da(_df,date_in_name):\n",
    "    \n",
    "    dtime = date_in_name.strftime('%Y%m%d%H%M%S')\n",
    "    \n",
    "    lon1 = _df.slon.values\n",
    "    lat1 = _df.slat.values\n",
    "    lon2 = _df.elon.values\n",
    "    lat2 = _df.elat.values\n",
    "\n",
    "    # Find/remove/replace missing data\n",
    "    keep = ~np.logical_or(lon1 == 0, lat1 == 0)\n",
    "    lon1 = lon1[keep]\n",
    "    lat1 = lat1[keep]\n",
    "    lon2 = lon2[keep]\n",
    "    lat2 = lat2[keep]\n",
    "    lon2[lon2 == 0] = lon1[lon2 == 0]\n",
    "    lat2[lat2 == 0] = lat1[lat2 == 0]\n",
    "\n",
    "    # Grid tornadoes\n",
    "    tornlines = G.grid_lines(sxs=lon1, sys=lat1, exs=lon2, eys=lat2)\n",
    "    all_mags = _df['all_weight']\n",
    "    sig_mags = _df['sig_weight']\n",
    "    all_fcst = G.make_empty_grid(dtype='float')\n",
    "    sig_fcst = G.make_empty_grid(dtype='float')\n",
    "    \n",
    "    for tornline, all_mag, sig_mag in zip(tornlines, all_mags, sig_mags):\n",
    "        all_fcst[tornline] = all_mag\n",
    "        sig_fcst[tornline] = sig_mag\n",
    "    \n",
    "    # Make practically perfect forecast\n",
    "    all_fcst = skmorph.binary_dilation(all_fcst, selem).astype(float)\n",
    "    sig_fcst = skmorph.binary_dilation(sig_fcst, selem).astype(float)\n",
    "\n",
    "    #print(np.max(fcst))\n",
    "    all_fcst = ndimage.gaussian_filter(all_fcst, 120/dx)\n",
    "    sig_fcst = ndimage.gaussian_filter(sig_fcst, 120/dx)\n",
    "    \n",
    "    # Degrade continuous probs into SPC prob\n",
    "    # Uncomment if regular probs\n",
    "    all_fcst[all_fcst < 0.02] = 0\n",
    "    all_fcst[np.logical_and(all_fcst < 0.05, all_fcst >= 0.02)] = 0.02\n",
    "    all_fcst[np.logical_and(all_fcst < 0.10, all_fcst >= 0.05)] = 0.05\n",
    "    all_fcst[np.logical_and(all_fcst < 0.15, all_fcst >= 0.10)] = 0.10\n",
    "    all_fcst[np.logical_and(all_fcst < 0.30, all_fcst >= 0.15)] = 0.15\n",
    "    all_fcst[np.logical_and(all_fcst < 0.45, all_fcst >= 0.30)] = 0.30\n",
    "    all_fcst[all_fcst >= 0.45] = 0.45\n",
    "\n",
    "    # Uncomment if sigtor probs\n",
    "    sig_fcst[sig_fcst < 0.10] = 0\n",
    "    sig_fcst[sig_fcst >= 0.10] = 0.10\n",
    "    \n",
    "    # Have this function call PAS function here\n",
    "    \n",
    "    return [all_fcst, sig_fcst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
